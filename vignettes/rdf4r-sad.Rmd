---
title: "RDF4R: An R Package for RDF Management.\nProgrammer's Documentation"
author: "Viktor Senderov"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rdf4r specification and design}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

RDF4R (`library(rdf4r)`) is an R package designed to enable the
R-practicioner to handle Resource Description Framework (RDF) data. This
is the programmer's documentation, i.e. the "specs and design sheet."

*Table of contents*

1. [Interfacing with a triple store](#interface-with-a-triple-store)
2. [Generating RDF](#create-identifiers-and-literals)

## Interface with a triple store

Connect, run queries on, and upload data to a triple store. Functions are separated into [low-level](#low-level-access) access functions that create connections, send raw data, read queries, and [high-level](#high-level-functions) functions that let you create specific functions for your project via factory functions.

### Low-level access

Here's an overview of the low-level access functions:

| Function | Purpose |
|----------|---------|
| [basic_triplestore_access(server_url, user, password, repository)](#connecting-to-a-triplestore) | connecting to a triplestore with no or basic auth |
| [api_triplestore_access(server_url, api_key, api_secret, repository)](#connecting-to-a-triplestore) | connecting to a triplestore with a secret key |
| [get_protocol_version(access_options)](#connecting-to-a-triplestore) | protocol version at endpoint |
| [list_repositories(access_options)](#working-with-repositories) | listing repositories at endpoint |
| [submit_sparql(query, access_options)](#submitting-data-and-querying-a-repository) | executing a SPARQL query |
| [add_data(rdf_data, access_options, data_format)](#submitting-data-and-querying-a-repository) | adding statements (e.g. Turtle) to a repo |

TODO: need submit_command against the update interface

##### Connecting to a triplestore

In order to access the triplestore, you first need to create a `triplestore_access_options` objects (internally a list). This object can be created by `basic_triplestore_access` in the case of no authentication or basic HTTP authentication or by `api_triplestore_access` in the case of API secret key authentication. They will fail if the URL or the authentication is wrong. The repository information can be omitted at this stage (see [list_repositories](#working-with-repositories)). In case of success the `$status` field of the list will be set to the protocol version. The protocol version can also be queried directly with `get_protocol_version`.

```{r}
# Access with basic HTTP authentication
graphdb = basic_triplestore_access(
  server_url = "http://graph.openbiodiv.net:7777",
  user = "dbuser",
  password = "public-access"
)

# Access with no authentication
graphdb2 = basic_triplestore_access(
  server_url = "http://graph.openbiodiv.net:7777"
)

# Access with API secret key authentication
graphdb3 = api_triplestore_access(
  server_url = "https://rdf.ontotext.com/4135593934/openbiodiv", 
  api_key = "s4bb1d43uc52",
  api_secret = "d7h7eg4e263ghss"
)

# Querying the protocol version for a triplestore endpoint.
get_protocol_version(graphdb)
```

##### Working with repositories

Use `list_repositories` to see what repositories the endpoint offers. The repo id's are given in the column `$id`. You can assign repo id's to the `$repository` field of the `triplestore_access_options` object.

```{r}
list_repositories(graphdb)
graphdb$repository = list_repositories(graphdb)$id[7]
```

##### Submitting data and querying a repository

After you've [selected an endpoint](#connecting-to-a-triplestore) and [a repository](#working-with-repositories), you can add Turtle data to it via `add_data` and submit a SPARQL query via `submit_sparql`. By default results are returned as a dataframe (`as_dataframe = TRUE`). If you override this parameter to `submit_sparql` the results are returned as a raw response that must be parsed (i.e. as JSON).

```{r}
# Submit a SPARQL query
query = "select * where {
  ?s ?p ?o .
  } limit 100"
submit_sparql(query = query, access_options = graphdb)

# Adds Seralized data to store
add_data("@prefix owl: <http://www.w3.org/2002/07/owl#>. \n <http://openbiodiv.net/sample_id> a owl:Thing.", access_options = graphdb)
```

### High-level functions

The premise of the high-level functions is to allow the programmer to create their own functions (closures) hiding the database access, the SPARQL code, and other details, and only having parameters of interest.

Here's an overview of the high-level functions:

| Function | Purpose |
|----------|---------|
| [query_factory(p_query, submit_function access_options, prefixes)](#manufacturing-read-and-UPDATE-query functions) | returns a parameterized function executing the query on the endpoint |
| [add_data_factory(access_options, prefixes)](#Manufacturing-add-data-functions) | Wraps `add_data` to simply submit a Turtle/Trig file to a triplestore |


##### Manufacturing READ and UPDATE query functions

The function `query_factory`'s purpose is to manufacture a function executing a specified SPARQL query against a specified endpoint. The SPARQL query that the function takes as an input

```{r}
p_query = "SELECT DISTINCT ?id WHERE {
  ?id rdfs:label '%label'
}"

p_query2 = "SELECT * WHERE {
  ?s ?p ?o
} LIMIT 100"

drop_query = "DROP GRAPH %subgraph"

simple_lookup = query_factory(p_query, access_options = graphdb)
simplest_f = query_factory(p_query2, access_options = graphdb)
drop_g = query_factory(drop_query, submit_function = submit_sparql_update, access_options = graphdb_secret)

simplest_f()
simple_lookup("Lyubomir Penev")
simple_lookup(label = "Pavel Stoev")
drop_g("<http://openbiodiv.net/123>")
```

Note that the queries are specified in a *parameterized format*. I.e. the strings indicated by `%<something>` will get replaced by the parameters of the manufactured function. There can be a query with no parameters. If you wish to see what are the arguments of a manufactured function later (as it has no manpage), you can use `args`. E.g.:

```{r}
args(simple_lookup)
```

##### Manufacturing add data functions

```{r}
prefixes = c(rdfs = "<http://www.w3.org/2000/01/rdf-schema#>", foaf = "<http://xmlns.com/foaf/0.1/>", openbiodiv = "<http://openbiodiv.net/>")
ttl = "openbiodiv:test_context {
openbiodiv:test1 rdf:label 'sample lab'@en .
}"
add_data_to_graphdb = add_data_factory(access_options = graphdb, prefixes = prefixes)
```

## Generating RDF

The basic building blocks of RDF are resource identifiers and atomic values
(literals). Identifiers and literals are stored as lists with certain
fields.

1. [identifier(id, prefix = NULL)](#identifier-consturction) 
2. [identifier_fun(label, fun = list(...), prefixes, def_prefix, ...)](#identifier-consturction)
3. [identifier_fun_factory(fun = list(...), prefixes, def_prefix, ...)](#identifier-construction)

##### Identifier Consturction

An identifier in the semantic web is something that uniquely identifies a
resource. Identifiers can be represented as URI's (e.g.
<http://example.com/id>), or as QNAME's (e.g. example:id). RDF4R stores
identifiers as lists with the following fields:

```{r}
sample_id = list(
  id  = "57d68e07-8315-4b30-9a8e-57226fd815d7",
  uri = "<http://openbiodiv.net/57d68e07-8315-4b30-9a8e-57226fd815d7>",
  qname = "openbiodiv:id",
  prefix = c(openbiodiv = "http://openbiodiv.net")  
)
```

`identifier` is the basic constructor function


, or via lookup in a triplestores with `lookup_identifier`:

```{r}
sample_id = identifier("57d68e07-8315-4b30-9a8e-57226fd815d7", prefix = c(openbiodiv = "http://openbiodiv.net"))


prefixes = c(
   rdfs = "http://www.w3.org/2000/01/rdf-schema#",
   foaf = "http://xmlns.com/foaf/0.1/",
   openbiodiv = "http://openbiodiv.net/",
   '_base' = "http://openbiodiv.net/"
  )

sample_id2 = lookup_identifier("Teodor Georgiev", prefixes = prefixes, f = simple_lookup)
```
